{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](001.jpg)\n",
    "![](002.jpg)\n",
    "![](003.jpg)\n",
    "![](004.jpg)\n",
    "![](005.jpg)\n",
    "![](006.jpg)\n",
    "![](007.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](008.jpg)\n",
    "![](009.jpg)\n",
    "![](010.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](011.jpg)\n",
    "![](012.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](013.jpg)\n",
    "![](014.jpg)\n",
    "![](015.jpg)\n",
    "![](016.jpg)\n",
    "![](017.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](018.jpg)\n",
    "![](019.jpg)\n",
    "![](020.jpg)\n",
    "![](021.jpg)\n",
    "![](022.jpg)\n",
    "![](023.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](024.jpg)\n",
    "![](025.jpg)\n",
    "![](026.jpg)\n",
    "![](027.jpg)\n",
    "![](028.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](029.jpg)\n",
    "![](030.jpg)\n",
    "![](031.jpg)\n",
    "![](032.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](033.jpg)\n",
    "![](33A.jpg)\n",
    "![](034.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Lecture #3 from this week, we provided an overview of non-probability sampling and some of the limitations of this type of approach for generating data and then making inferences about larger populations based on the data. While non-probability sampling methods can generate a lot of data very quickly and at low cost, analysts of the data must be very careful when making population inferences based on the data. There are many pitfalls to making these larger conclusions based on data generated using this technique, and here we consider a rather spectacular failure of this approach for trying to make statements about larger populations.\n",
    "\n",
    "In 2008, researchers studied the potential of analyzing Google searches to try and understand the spatial and temporal distribution of a flu epidemic. The researchers wanted to see if the analysis of Google searches could effectively replicate the conclusions that CDC researchers were finding based on analyses of data from formal probability samples of the U.S. population. At first, the findings seemed to be almost in exact alignment with the CDC data, and this was viewed as a tremendous success of “big data”. However, these findings were based on a limited window of time. As people continued to study the Google data relative to CDC data, substantial differences emerged, and the Google data was largely viewed as providing a misleading picture of the spread of the flu virus during that time period. This study received a great deal of coverage in the popular press: for more details, take a look at this article: https://www.wired.com/2015/10/can-learn-epic-failure-google-flu-trends/.\n",
    "\n",
    "The point of this example is not to say that all non-probability samples will lead to erroneous conclusions. When carefully and properly applying one of the two inferential approaches introduced in Lecture #3, one can make sound conclusions about the features of a larger population. In another very popular example, Wang and colleagues analyzed hundreds of thousands of survey responses from Xbox users in 2012, and used a type of calibration weighting approach to make conclusions about voting intentions of the population. Their estimates of preference for presidential candidates in the 2012 election were almost spot-on with forecasts based on aggregation of polling data. For more on this study, please see this link: https://www.sciencedirect.com/science/article/pii/S0169207014000879?via%3Dihub.\n",
    "\n",
    "In short, it is always important to first ask what type of sampling mechanism was used to generate the data set that is presently under consideration. Then, if non-probability sampling methods were used, careful analyses of how representative that sample is with respect to the target population of interest are necessary before proceeding. We will consider analytic techniques for these types of data in more detail in future lectures.\n",
    "\n",
    "**Additional Deep-Dive Readings on Non-Probability Sampling**\n",
    "\n",
    "Baker, R., Brick, J.M., Bates, N.A., Battaglia, M., Couper, M.P., Dever, J.A., Gile, K.J., and Tourangeau, R. (2013). Report of the AAPOR Task Force on Non-Probability Sampling. American Association for Public Opinion Research, May 2013. Available from www.aapor.org.\n",
    "\n",
    "Elliott, M.R. and Valliant, R. (2017). Inference for Non-Probability Samples. Statistical Science, 32(2), 249-264.\n",
    "\n",
    "Pasek, J. (2015). When Will Nonprobability Surveys Mirror Probability Surveys? Considering Types of Inference and Weighting Strategies as Criteria for Correspondence. International Journal of Public Opinion Research. doi:10.1093/ijpor/edv016.\n",
    "\n",
    "Wang, W., Rothschild, D., Goel, S., and Gelman, A. (2014). Forecasting elections with non-representative polls. International Journal of Forecasting, 31(3), 980-991."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](035.jpg)\n",
    "![](036.jpg)\n",
    "![](037.jpg)\n",
    "![](038.jpg)\n",
    "![](039.jpg)\n",
    "![](040.jpg)\n",
    "![](041.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many so-called “standard” statistical analyses that are presented and discussed in introductory statistics courses make the assumption that the data of interest are independent and identically distributed (or “i.i.d.”) observations. As discussed in the lectures earlier this week, simple random sampling (SRS) is the closest probability sampling analog to i.i.d., in that the sampling mechanism used to generate the observations will produce independent and identically distributed observations. While this type of sampling will produce samples with this nice “i.i.d.” statistical property, facilitating “standard” statistical analyses, SRS is seldom used when sampling from real populations. One of the reasons for this is that SRS, while producing estimates that are unbiased in nature (which recall means that the estimates based on hypothetical repeated samples using SRS will have a mean equal to the true population mean), has the potential to generate “bad” samples with substantial sampling error (where an estimate based on the sample is quite different from the population parameter of interest).\n",
    "\n",
    "Consider, for example, a national sample of 1,000 cell phone numbers selected using SRS. While in expectation any one given sample will include a representative random sampling of numbers from area codes across the nation, all possible random samples using SRS are equally likely. What this means is that a simple random sample of cell phone numbers that only includes area codes from Florida is just as likely as a simple random sample of numbers that includes a representative selection across the states. Ideally, we would like to use design strategies to reduce the chances of such a “bad sample” occurring, especially if our variable of interest tends to take on very different values in the state of Florida! The major statistical problem with the simple random “Florida” sample is that any estimate that we compute after collecting data from the sample will likely be very different from the true population parameter that we are trying to estimate (especially if the variable of interest tends to take on very different values in Florida relative to the rest of the nation). Because the probability of selecting these extreme samples is equal to the probability of selecting more representative samples, the sampling distribution for simple random samples can tend to be quite variable.\n",
    "\n",
    "A very common sampling technique used to minimize the sampling variance that can arise from these so-called “bad samples” in SRS is stratification. You’ve already been introduced to stratification in an earlier lecture. When we conduct stratified sampling, we first allocate portions of our sample to all possible divisions (or “strata”) of the population of interest (e.g., states). This ensures that some sample will be selected from all of these possible divisions, and that the overall sample will therefore be representative of the target population. For example, using a technique known as proportionate allocation, suppose that we knew that 55% of students enrolled in a particular college were females, and 45% were males. If we wanted to draw a sample of 1,000 students from this college, we would randomly selected 550 females from a list of all females enrolled, and 450 males from a list of all males enrolled. This ensures that our entire sample of size 1,000 won’t include only females!\n",
    "\n",
    "Consider our earlier gym example as well, and the web app that allowed us to visualize sampling distributions. If we only draw our sample from one stratum of the overall population (e.g., gym goers), and the units in that stratum tend to have values on a variable of interest that differ from the values for the variable in other strata, then the estimates that we compute based on that sample will be biased, and will not represent the overall target population. This is an example of selection bias; on average, estimates computed from repeated samples of gym goers will not be equal to the true population parameter of interest. Stratified sampling ensures that we would select a sample of gym goers and a sample of non-gym goers, increasing the representativeness of our sample and potentially reducing bias.\n",
    "\n",
    "Another nice property of stratified sampling is that it shrinks the variance of sampling distributions. In SRS, all of the variance within strata and between strata in terms of the variable of interest contributes to the overall sampling variance. In stratified sampling, when we allocate a certain number of sampled units to be selected from each stratum, we remove the between-stratum variance from the overall sampling variance! This is because every hypothetical repeated sample would use the same stratified design, and the same allocation; assuming reasonable response rates, we will have representation from each of the strata where we allocated a portion of the sample. There is no uncertainty in whether we will have sampled units from a particular stratum, and there is nothing random about the allocations; these are fixed by design! The only uncertainty arises from the random sampling that occurs within strata from one hypothetical sample to another. Each sample will always feature random selections from the same strata; what happens within the strata will change from sample to sample.\n",
    "\n",
    "We will revisit the idea of stratified sampling in an upcoming lecture, but you will often hear sampling statisticians say “when in doubt, stratify.” We can use this technique to prevent bad samples, and decrease the variance of our sampling distributions.\n",
    "\n",
    "Bad Samples Arising from Nonresponse\n",
    "When analyzing data, we always have to think carefully about the process used to ultimately produce the data that we are analyzing. We may dedicate substantial resources to a carefully designed stratified sample of some population that will produce unbiased estimates by design; however, there is no guarantee that every unit sampled will agree to provide data. If a sampled unit refuses to provide data after being sampled, this situation is known as unit nonresponse. Unit nonresponse can have a particularly negative impact on the quality of a given sample when the units that ultimately agree to provide data differ significantly from the units that do not agree to provide data on the variables of interest.\n",
    "\n",
    "For example, suppose that people with lower income tend to respond to a survey of a nationally representative sample of individuals at higher rates than people with higher income. Because the resulting sample of respondents to the survey request tends to feature people with lower income, any estimates related to income (which will always be computed using data from the respondents, or the units that agree to provide data!) will be subject to another form of selection bias, namely nonresponse bias. In short, nonresponse bias occurs when there is a tendency for the units in a sample that agree to provide data to be systematically different from the units in the sample that do not provide data (in terms of the variable of interest). This type of bias can also occur for estimates based on specific variables, when sampled units may agree to provide data in general, but not on specific variables. For instance, a survey respondent may agree to participate in the survey, but refuse to share their income. This type of nonresponse is known as item nonresponse.\n",
    "\n",
    "Whereas stratified sampling is a design tool that can be used to reduce selection bias from a sampling perspective, the selection bias introduced by unit or item nonresponse can either be addressed during the data collection process or via post-survey adjustments to the estimates based on a respondent sample. For example, sampled units reluctant to provide data may be offered additional incentives for their participation, or offered different methods for providing their data (e.g., over the web, rather than speaking to an interviewer). Such units may also receive additional effort from a data collection organization (e.g., more follow-up contact attempts). After the survey is over, if there is still evidence that the respondent sample somehow differs systematically from the full sample, respondents who had a lower probability of responding may receive larger weight in the overall analysis. Item nonresponse may be addressed via statistical models used to predict the missing values as a function of other observed data. There are all tools designed to reduce the type of selection bias that can arise from nonresponse.\n",
    "\n",
    "It is essential that anyone computing estimates based on samples of populations carefully evaluate the steps that were taken to minimize the potential biases arising from these “bad” samples.\n",
    "\n",
    "Additional Deep-Dive Readings on Stratified Sampling and Nonresponse Bias\n",
    "Groves, R. M., Fowler Jr, F. J., Couper, M. P., Lepkowski, J. M., Singer, E., & Tourangeau, R. (2011). Survey Methodology, Second Edition. John Wiley & Sons.\n",
    "\n",
    "Heeringa, S.G., West, B.T., and Berglund, P.A. (2017). Applied Survey Data Analysis, Second Edition. Chapman Hall / CRC Press.\n",
    "\n",
    "Kish, Leslie. (1965). Survey Sampling. Wiley.\n",
    "\n",
    "Lohr, Sharon. (1999). Sampling: Design and Analysis, Second Edition. Cengage Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](042.jpg)\n",
    "![](043.jpg)\n",
    "![](044.jpg)\n",
    "![](045.jpg)\n",
    "![](046.jpg)\n",
    "![](047.jpg)\n",
    "![](048.jpg)\n",
    "![](049.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](050.jpg)\n",
    "![](051.jpg)\n",
    "![](052.jpg)\n",
    "![](053.jpg)\n",
    "![](054.jpg)\n",
    "![](055.jpg)\n",
    "![](056.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
